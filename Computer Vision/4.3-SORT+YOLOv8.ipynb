{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abbb4f-e7eb-4961-ac72-164e4262a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1336d-549e-4b11-9d3f-f4f5fb9df31d",
   "metadata": {},
   "source": [
    "## Simple Online Real Time tracking(sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72455ff7-8aa0-46b4-9b34-8588cf6e871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from sort import Sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6676013-be29-41c1-95e8-3059525d701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 model optimized for real-time processing.\n",
    "yolo_model = YOLO(\"yolov8n.pt\") \n",
    "#yolov8 nano version-light weight for working with CPU\n",
    "\n",
    "# Initialize SORT tracker\n",
    "tracker = Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51c8b70-cc19-43f2-926b-e1ee636e787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video source (0 for webcam, or provide video file path)\n",
    "# video_path = 'video.mp4' \n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#if wants to work with webcam\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8cefe0c-2fae-4821-beb6-3492746ba7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 254.7ms\n",
      "Speed: 32.0ms preprocess, 254.7ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.1ms\n",
      "Speed: 5.4ms preprocess, 147.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 134.1ms\n",
      "Speed: 3.0ms preprocess, 134.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.5ms\n",
      "Speed: 2.8ms preprocess, 133.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.6ms\n",
      "Speed: 2.8ms preprocess, 141.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.5ms\n",
      "Speed: 3.0ms preprocess, 123.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.2ms\n",
      "Speed: 2.3ms preprocess, 149.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.6ms\n",
      "Speed: 2.9ms preprocess, 144.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.4ms\n",
      "Speed: 3.1ms preprocess, 131.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.8ms\n",
      "Speed: 2.6ms preprocess, 139.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.4ms\n",
      "Speed: 2.8ms preprocess, 124.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.5ms\n",
      "Speed: 2.2ms preprocess, 133.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 140.8ms\n",
      "Speed: 2.8ms preprocess, 140.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.2ms\n",
      "Speed: 2.5ms preprocess, 146.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 138.8ms\n",
      "Speed: 2.9ms preprocess, 138.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.4ms\n",
      "Speed: 2.7ms preprocess, 139.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.3ms\n",
      "Speed: 2.8ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 130.0ms\n",
      "Speed: 3.4ms preprocess, 130.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.7ms\n",
      "Speed: 3.2ms preprocess, 135.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 138.4ms\n",
      "Speed: 3.5ms preprocess, 138.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.9ms\n",
      "Speed: 2.5ms preprocess, 125.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 2.0ms preprocess, 144.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.9ms\n",
      "Speed: 4.8ms preprocess, 168.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 146.7ms\n",
      "Speed: 3.2ms preprocess, 146.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.8ms\n",
      "Speed: 1.9ms preprocess, 144.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 138.0ms\n",
      "Speed: 2.9ms preprocess, 138.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.5ms\n",
      "Speed: 3.3ms preprocess, 126.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.8ms\n",
      "Speed: 2.7ms preprocess, 124.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.3ms\n",
      "Speed: 3.1ms preprocess, 125.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.3ms\n",
      "Speed: 2.7ms preprocess, 131.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 133.2ms\n",
      "Speed: 2.6ms preprocess, 133.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.4ms\n",
      "Speed: 3.0ms preprocess, 123.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 119.0ms\n",
      "Speed: 4.3ms preprocess, 119.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.3ms\n",
      "Speed: 2.9ms preprocess, 116.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.3ms\n",
      "Speed: 2.7ms preprocess, 125.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 123.1ms\n",
      "Speed: 2.1ms preprocess, 123.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.1ms\n",
      "Speed: 3.4ms preprocess, 126.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 118.8ms\n",
      "Speed: 1.9ms preprocess, 118.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 139.7ms\n",
      "Speed: 4.1ms preprocess, 139.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "#Reads continuous video frames\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run YOLOv8 detection\n",
    "    results = yolo_model(frame)\n",
    "    detections = [] \n",
    "    \n",
    "    for result in results:\n",
    "        for box in result.boxes.data:\n",
    "            x1, y1, x2, y2, conf, cls = box.tolist()\n",
    "            detections.append([x1, y1, x2, y2, conf])\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    detections = np.array(detections) \n",
    "    \n",
    "    # Update tracker\n",
    "    tracked_objects = tracker.update(detections)\n",
    "    \n",
    "    # Draw tracking boxes\n",
    "    for obj in tracked_objects:\n",
    "        x1, y1, x2, y2, track_id = obj.astype(int)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"ID {track_id}\", (x1, y1 - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display output\n",
    "    cv2.imshow(\"Object Tracking\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"): \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690cc59-9b28-41a0-aed0-9d9ff5436475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
