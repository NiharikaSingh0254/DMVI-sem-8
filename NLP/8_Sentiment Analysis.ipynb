{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcT3pgZ8F5vZ"
   },
   "source": [
    "# **Q1. Problem Statement: Sentiment Analysis**<br>\n",
    "Write a Python program that reads the mood_data.txt.<br> The following are the given tasks, that has to be taken into\n",
    "consideration while constructing the solution.<br>\n",
    "Here dataset contains two columns where one is our target <br>(“emotion” has 6\n",
    "different categories) and another is the independent variable (“Text” contains\n",
    "data in form of sentences).\n",
    "1. Load the mobile mood_data.txt data into a DataFrame\n",
    "2. Generate tokens and remove punctuations, stop words and lower all rows\n",
    "3. Join all the tokens as they were before and store them in a new column named\n",
    "“cleaned_text”\n",
    "4. Now remove all single characters, extra space, and special characters and<br>\n",
    "store processed data in a new column named “processed_text”\n",
    "5. Create a final DataFrame containing dependent variable(emotion) and\n",
    "processed text\n",
    "6. Extract independent variables (Xs) and dependent variables (Ys) into separate<br>\n",
    "data objects\n",
    "7. Generate tokens and do vectorization\n",
    "\n",
    "8. Build a model with Multinomial Naive Bayes, Random Forest, Random Forest <br>\n",
    "(Entropy), SVM and compare their accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhBr7mwMF5vf",
    "outputId": "ede2f4a4-8658-45ff-bd1b-9c4abd154cfd"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4ra32YQG9U5"
   },
   "source": [
    "**Step-1:** Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EKDoxP5F5vh"
   },
   "outputs": [],
   "source": [
    "# Load the required libraries from Python\n",
    "# Make sure all the libraries have been download else download using nltk.download command\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o_vuZ60F5vi"
   },
   "source": [
    "**Step-2:** Loading sample data set into dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDhBoFDyF5vi"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('mood_data.txt', names=['Text', 'Emotion'], sep=';') # load the dataset onto the google colab file section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOpsMZeUF5vj",
    "outputId": "e41ae291-149f-4ef3-99f3-0b2f9a30f67b"
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eBEaigF6F5vk",
    "outputId": "0257e165-fb54-40f6-cdf0-7169074c9315"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0EO-sCyF5vk"
   },
   "source": [
    "**Step-3:** Generating tokens and remove punctuations, stop words and converting all rows to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJbaEX2XF5vl"
   },
   "outputs": [],
   "source": [
    "# Load the required libraries for cleaning\n",
    "import string,re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7SISoiDF5vm"
   },
   "outputs": [],
   "source": [
    "# Create a function to generate cleaned data from raw text\n",
    "def clean_text(mood):\n",
    "    mood = word_tokenize(mood) # Create tokens\n",
    "    mood= \" \".join(mood) # Join tokens\n",
    "    mood = [char for char in mood if char not in string.punctuation] # Remove punctuations\n",
    "    mood = ''.join(mood) # Join the leters\n",
    "    mood = [word for word in mood.split() if mood.lower() not in stopwords.words('english')] # Remove common english words (I, you, we,...)\n",
    "    return \" \".join(mood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weZ8ojONF5vm"
   },
   "source": [
    "**Step-4:** Storing new data in cleaned_text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "1RPKbPwLF5vm",
    "outputId": "601e1224-31d5-4615-b28d-951c22f0b688"
   },
   "outputs": [],
   "source": [
    "# Apply the function to 'text' to clean it\n",
    "# Add cleaned data as a separate column to the DataFrame\n",
    "df_train['cleaned_text'] = df_train['Text'].apply(clean_text)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYiwo30_F5vn",
    "outputId": "1517258a-bff2-43f2-fefe-2b469228a102"
   },
   "outputs": [],
   "source": [
    "df_train[\"cleaned_text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX0IPDbKF5vn"
   },
   "source": [
    "**Step-4:** Removing special charachters,extra space,and convert into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhrm_XheF5vo"
   },
   "outputs": [],
   "source": [
    "features = df_train['cleaned_text']\n",
    "processed_features = []\n",
    "\n",
    "for sentence in range(0, len(features)):\n",
    "    # Remove all the special characters\n",
    "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
    "    \n",
    "    # Remove single characters appearing in the text except the start\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "    \n",
    "    # Remove single characters appearing at the start\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "    \n",
    "    # Substitute multiple spaces with a single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "    \n",
    "    \n",
    "    # Convert to lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "\n",
    "    processed_features.append(processed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJMTWRP9F5vo",
    "outputId": "fcc8cd97-1325-40e1-f817-5919a2b65f6e"
   },
   "outputs": [],
   "source": [
    "# Print first five values of processed data\n",
    "processed_features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqQe-g67F5vp"
   },
   "source": [
    "**Step-5:** Saving the above processed data into processed_text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "V0wZ82ASF5vp",
    "outputId": "499085f7-5b4a-4b62-9b78-1a7f65be7158"
   },
   "outputs": [],
   "source": [
    "# Add the processed data as a separate column to the DataFrame\n",
    "\n",
    "df_train['processed_text'] = processed_features\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcIJ90fXF5vp"
   },
   "source": [
    "**Step-6:** Extracting processed_text and Emotion then creating final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "f0PjWX6-F5vq",
    "outputId": "74d3e437-6f24-44ca-8ac6-2f4544f1f4bd"
   },
   "outputs": [],
   "source": [
    "final_df = df_train[[\"processed_text\",\"Emotion\"]]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC0_hS2oF5vq"
   },
   "source": [
    "**Step-7:** Generating tokens and doing vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBC6hdsEF5vq"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text using TweetTokenizer from NLTK\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlTqw1oSF5vr"
   },
   "outputs": [],
   "source": [
    "# Function to generate tokens using TweetTokenizer\n",
    "def tokenize(text): \n",
    "    tk = TweetTokenizer()\n",
    "    return tk.tokenize(text)\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word',tokenizer = tokenize,lowercase = True,ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R76lf62qF5vr"
   },
   "outputs": [],
   "source": [
    "# Generate unique words from the processed data by applying Count Vectorizer along with TweetTokenizer\n",
    "count= vectorizer.fit_transform(final_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VM_YnIYF5vr",
    "outputId": "ceeccd6d-fba0-4c24-8b10-0a32e83629cb"
   },
   "outputs": [],
   "source": [
    "# What is the shape of the data- Count vectorizer provides information about unique words present in data\n",
    "count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xvx4aVBjF5vr"
   },
   "outputs": [],
   "source": [
    "# Load the libraries required for performing classification\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gps2u8hF5vr"
   },
   "source": [
    "**Step-8:** Spliting the data into training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruX8CT5RF5vs"
   },
   "outputs": [],
   "source": [
    "# Use processed data as independent variable and polarity as dependent variable\n",
    "\n",
    "X = final_df['processed_text'].values\n",
    "y = final_df['Emotion'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=100, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRbABa5YF5vs"
   },
   "source": [
    "**Step-9:** Doing vectorization for training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ns_veV1jF5vs"
   },
   "outputs": [],
   "source": [
    "# Extract features using TFIDF Vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_idf = vectorizer.fit_transform(X_train)\n",
    "X_test_idf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "b1Bf8MXWF5vs",
    "outputId": "79a02a8e-1533-4658-cebb-822620f9153b"
   },
   "outputs": [],
   "source": [
    "# Print idf values\n",
    "df_idf = pd.DataFrame(vectorizer.idf_, index=vectorizer.get_feature_names_out(),columns=[\"idf_weights\"])\n",
    "# Sort ascending\n",
    "df_idf.sort_values(by=['idf_weights'],ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kT7ijSpF5vt"
   },
   "source": [
    "**Step-10:** Model building(generate asked model) and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpieU00GF5vt",
    "outputId": "c70703ef-08db-4a43-a87a-e0ef08fa7abc"
   },
   "outputs": [],
   "source": [
    "# Perform Multinomial Naive Bayes Classification\n",
    "# Apply MultinomialNB on training data\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70jQsvjJF5vt",
    "outputId": "e0cd00ce-e193-4e3d-ebff-d07563c7d6fd"
   },
   "outputs": [],
   "source": [
    "# Predict polarity by fitting the model to testing data\n",
    "pred_mnb = mnb.predict(X_test_idf)\n",
    "\n",
    "# Calculate accuracy of predicted values\n",
    "acc = accuracy_score(y_test, pred_mnb)\n",
    "\n",
    "\n",
    "results = pd.DataFrame([['Multinomial Naive Bayes', acc]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jh4i3tKNF5vt",
    "outputId": "f942e059-a898-4cad-e603-205ff3506037"
   },
   "outputs": [],
   "source": [
    "# Perform Random Forest classification on the processed data and compare the accuracy score of both these models\n",
    "\n",
    "# Random Forest Classifier with 'gini'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(X_train_idf, y_train)\n",
    "\n",
    "# Predict using testing data\n",
    "y_pred_rf = clf_rf.predict(X_test_idf)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest(Gini)', acc]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "\n",
    "results = pd.concat([results,model_results], ignore_index = True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xX7wwZUNF5vu"
   },
   "outputs": [],
   "source": [
    "# Random Forest Classifier with 'entropy'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(criterion='entropy')\n",
    "clf_rf.fit(X_train_idf, y_train)\n",
    "\n",
    "# Predict using testing data\n",
    "y_pred_rf = clf_rf.predict(X_test_idf)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest(Entropy)', acc]],\n",
    "               columns = ['Model',  'Accuracy'])\n",
    "\n",
    "results = pd.concat([results,model_results], ignore_index = True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2kg62kKF5vu",
    "outputId": "b3a1dad9-3c9e-42a5-a4e5-84aec2fad298"
   },
   "outputs": [],
   "source": [
    "#svm model\n",
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC()\n",
    "clf_svc.fit(X_train_idf, y_train)\n",
    "\n",
    "# Predict using testing data\n",
    "y_pred_rf = clf_svc.predict(X_test_idf)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "model_results = pd.DataFrame([['SVC by SVM ', acc]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "\n",
    "results = pd.concat([results,model_results], ignore_index = True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U06xjADOF5vu",
    "outputId": "4e817ced-62dc-4bc0-8cab-26bea15d6649"
   },
   "outputs": [],
   "source": [
    "# Display confusion matrix for Random Forest\n",
    "\n",
    "confusion_matrix(y_test,y_pred_rf) ### Confusion matrix for Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLdWf_KaEX-h"
   },
   "source": [
    "**Conclusion** : Random forrest classifier has performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_D47_DIY_Solution_V1_0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
