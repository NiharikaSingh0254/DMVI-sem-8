{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. Problem Statement: NLP text processing**\n",
    "\n",
    "Write a Python program that reads the demotext.bxt text file\n",
    "\n",
    "The following are the tasks that are to be taken into consideration while constructing the solution for text processing using the NLTK library.\n",
    "\n",
    "1. Load the demotext.bxd text file into a variable and then close the file\n",
    "\n",
    "2. Do word wise tokenization list out generated tokens\n",
    "\n",
    "3. Transform each loken into a small case\n",
    "\n",
    "4. Remove stop words from the generated token list\n",
    "\n",
    "5. Remove extra symbols like commas, full stops, and question marks using a regular expression tokenizer and store them in another variable\n",
    "\n",
    "6. Do bigram and trigram for generated tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# the download() function will help in downloading the corpus present in the nltk library\n",
    "# nltk.download()\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Download 'punkt'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\divu2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\divu2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Load given textfile into variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Lorem Ipsum?\n",
      "\n",
      "Lorem Ipsum is simply dummy text of the printing and \n",
      "typesetting industry. Lorem Ipsum has been the industry's \n",
      "standard dummy text ever since the 1500s, when an unknown \n",
      "printer took a galley of type and scrambled it to make a \n",
      "type specimen book. It has survived not only five centuries, \n",
      "but also the leap into electronic typesetting, \n",
      "remaining essentially unchanged. \n",
      "\n",
      "It was popularised in the 1960s with the release of Letraset \n",
      "sheets containing Lorem Ipsum passages, and more recently \n",
      "with desktop publishing software like Aldus PageMaker \n",
      "including versions of Lorem Ipsum.\n"
     ]
    }
   ],
   "source": [
    "f=open('demotext (1).txt','r')\n",
    "\n",
    "# read whole file to a string\n",
    "data = f.read()\n",
    "\n",
    "# close the file\n",
    "f.close()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Do word wise tokenization list out generated tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'Lorem', 'Ipsum', '?', 'Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.', 'Lorem', 'Ipsum', 'has', 'been', 'the', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.', 'It', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.', 'It', 'was', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'of', 'Lorem', 'Ipsum', '.']\n"
     ]
    }
   ],
   "source": [
    "# 2. Do word wise tokenization list out generated tokens\n",
    "words = nltk.word_tokenize(data)\n",
    "print(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Transform each token into a small case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'lorem', 'ipsum', '?', 'lorem', 'ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.', 'lorem', 'ipsum', 'has', 'been', 'the', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.', 'it', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.', 'it', 'was', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'letraset', 'sheets', 'containing', 'lorem', 'ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'including', 'versions', 'of', 'lorem', 'ipsum', '.']\n"
     ]
    }
   ],
   "source": [
    "# 5. Transform each loken into a small case\n",
    "words = [word.lower() for word in words]\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Remove stop words from the generated token list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lorem', 'ipsum', '?', 'lorem', 'ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', '.', 'lorem', 'ipsum', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', '1500s', ',', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'type', 'specimen', 'book', '.', 'survived', 'five', 'centuries', ',', 'also', 'leap', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.', 'popularised', '1960s', 'release', 'letraset', 'sheets', 'containing', 'lorem', 'ipsum', 'passages', ',', 'recently', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'including', 'versions', 'lorem', 'ipsum', '.']\n"
     ]
    }
   ],
   "source": [
    "# 4. Remove stop words from the generated token list\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "print(filtered_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Remove extra symbols like commas, full stops, and question marks using a regular expression tokenizer and store them in another variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'Lorem', 'Ipsum', 'Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', 'Lorem', 'Ipsum', 'has', 'been', 'the', 'industry', 's', 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', 'It', 'has', 'survived', 'not', 'only', 'five', 'centuries', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', 'remaining', 'essentially', 'unchanged', 'It', 'was', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'of', 'Lorem', 'Ipsum']\n"
     ]
    }
   ],
   "source": [
    "# 7. Remove extra symbols like commas, full stops, and question marks using a regular expression tokenizer and store them in another variable\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = tokenizer.tokenize(data)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. Do bigram and trigram for generated tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams: [('What', 'is'), ('is', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', 'is'), ('is', 'simply'), ('simply', 'dummy'), ('dummy', 'text'), ('text', 'of'), ('of', 'the'), ('the', 'printing'), ('printing', 'and'), ('and', 'typesetting'), ('typesetting', 'industry'), ('industry', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', 'has'), ('has', 'been'), ('been', 'the'), ('the', 'industry'), ('industry', 's'), ('s', 'standard'), ('standard', 'dummy'), ('dummy', 'text'), ('text', 'ever'), ('ever', 'since'), ('since', 'the'), ('the', '1500s'), ('1500s', 'when'), ('when', 'an'), ('an', 'unknown'), ('unknown', 'printer'), ('printer', 'took'), ('took', 'a'), ('a', 'galley'), ('galley', 'of'), ('of', 'type'), ('type', 'and'), ('and', 'scrambled'), ('scrambled', 'it'), ('it', 'to'), ('to', 'make'), ('make', 'a'), ('a', 'type'), ('type', 'specimen'), ('specimen', 'book'), ('book', 'It'), ('It', 'has'), ('has', 'survived'), ('survived', 'not'), ('not', 'only'), ('only', 'five'), ('five', 'centuries'), ('centuries', 'but'), ('but', 'also'), ('also', 'the'), ('the', 'leap'), ('leap', 'into'), ('into', 'electronic'), ('electronic', 'typesetting'), ('typesetting', 'remaining'), ('remaining', 'essentially'), ('essentially', 'unchanged'), ('unchanged', 'It'), ('It', 'was'), ('was', 'popularised'), ('popularised', 'in'), ('in', 'the'), ('the', '1960s'), ('1960s', 'with'), ('with', 'the'), ('the', 'release'), ('release', 'of'), ('of', 'Letraset'), ('Letraset', 'sheets'), ('sheets', 'containing'), ('containing', 'Lorem'), ('Lorem', 'Ipsum'), ('Ipsum', 'passages'), ('passages', 'and'), ('and', 'more'), ('more', 'recently'), ('recently', 'with'), ('with', 'desktop'), ('desktop', 'publishing'), ('publishing', 'software'), ('software', 'like'), ('like', 'Aldus'), ('Aldus', 'PageMaker'), ('PageMaker', 'including'), ('including', 'versions'), ('versions', 'of'), ('of', 'Lorem'), ('Lorem', 'Ipsum')]\n",
      "trigrams: [('What', 'is', 'Lorem'), ('is', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', 'Lorem'), ('Ipsum', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', 'is'), ('Ipsum', 'is', 'simply'), ('is', 'simply', 'dummy'), ('simply', 'dummy', 'text'), ('dummy', 'text', 'of'), ('text', 'of', 'the'), ('of', 'the', 'printing'), ('the', 'printing', 'and'), ('printing', 'and', 'typesetting'), ('and', 'typesetting', 'industry'), ('typesetting', 'industry', 'Lorem'), ('industry', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', 'has'), ('Ipsum', 'has', 'been'), ('has', 'been', 'the'), ('been', 'the', 'industry'), ('the', 'industry', 's'), ('industry', 's', 'standard'), ('s', 'standard', 'dummy'), ('standard', 'dummy', 'text'), ('dummy', 'text', 'ever'), ('text', 'ever', 'since'), ('ever', 'since', 'the'), ('since', 'the', '1500s'), ('the', '1500s', 'when'), ('1500s', 'when', 'an'), ('when', 'an', 'unknown'), ('an', 'unknown', 'printer'), ('unknown', 'printer', 'took'), ('printer', 'took', 'a'), ('took', 'a', 'galley'), ('a', 'galley', 'of'), ('galley', 'of', 'type'), ('of', 'type', 'and'), ('type', 'and', 'scrambled'), ('and', 'scrambled', 'it'), ('scrambled', 'it', 'to'), ('it', 'to', 'make'), ('to', 'make', 'a'), ('make', 'a', 'type'), ('a', 'type', 'specimen'), ('type', 'specimen', 'book'), ('specimen', 'book', 'It'), ('book', 'It', 'has'), ('It', 'has', 'survived'), ('has', 'survived', 'not'), ('survived', 'not', 'only'), ('not', 'only', 'five'), ('only', 'five', 'centuries'), ('five', 'centuries', 'but'), ('centuries', 'but', 'also'), ('but', 'also', 'the'), ('also', 'the', 'leap'), ('the', 'leap', 'into'), ('leap', 'into', 'electronic'), ('into', 'electronic', 'typesetting'), ('electronic', 'typesetting', 'remaining'), ('typesetting', 'remaining', 'essentially'), ('remaining', 'essentially', 'unchanged'), ('essentially', 'unchanged', 'It'), ('unchanged', 'It', 'was'), ('It', 'was', 'popularised'), ('was', 'popularised', 'in'), ('popularised', 'in', 'the'), ('in', 'the', '1960s'), ('the', '1960s', 'with'), ('1960s', 'with', 'the'), ('with', 'the', 'release'), ('the', 'release', 'of'), ('release', 'of', 'Letraset'), ('of', 'Letraset', 'sheets'), ('Letraset', 'sheets', 'containing'), ('sheets', 'containing', 'Lorem'), ('containing', 'Lorem', 'Ipsum'), ('Lorem', 'Ipsum', 'passages'), ('Ipsum', 'passages', 'and'), ('passages', 'and', 'more'), ('and', 'more', 'recently'), ('more', 'recently', 'with'), ('recently', 'with', 'desktop'), ('with', 'desktop', 'publishing'), ('desktop', 'publishing', 'software'), ('publishing', 'software', 'like'), ('software', 'like', 'Aldus'), ('like', 'Aldus', 'PageMaker'), ('Aldus', 'PageMaker', 'including'), ('PageMaker', 'including', 'versions'), ('including', 'versions', 'of'), ('versions', 'of', 'Lorem'), ('of', 'Lorem', 'Ipsum')]\n"
     ]
    }
   ],
   "source": [
    "# 8. Do bigram and trigram for generated tokens\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "bigrams = list(nltk.bigrams(tokens))\n",
    "trigrams = list(nltk.trigrams(tokens))\n",
    "\n",
    "print(\"bigrams:\",bigrams)\n",
    "print(\"trigrams:\",trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
