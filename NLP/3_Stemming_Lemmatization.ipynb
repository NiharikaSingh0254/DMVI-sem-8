{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q1. Problem Statement: Stemming, Lemmatization and Word sense Disambiguation**\n",
    "\n",
    "Perform the following tasks to get an understanding of stemming, lemmatization and Word Sense Disambiguation (WSD) using the Natural Language Tool Kit (NLTK)\n",
    "\n",
    "1. Declare a list of words and perform stemming on each word using PorterStemmer() and LancasterStemmer()\n",
    "\n",
    "2. Declare a sentence and perform lemmatization on each word of the sentence using WordNetLemmetizer()\n",
    "\n",
    "3. Declare two different sentences with homonyms and perform WSD to fetch the meanings of the homonyms in the context of their respective sentences\n",
    "\n",
    "Note: Homonyms are words that have the same spelling and pronunciation, but differentÂ meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1. Importing necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2. Creating a PorterStemmer() & LancasterStemmer() objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=PorterStemmer()\n",
    "lancaster=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3. Stemming the words using PorterStemmer and LancasterStemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original Word List\n",
      "['friend', 'friendship', 'friends', 'friendships', 'stabil', 'destabilize', 'misunderstanding', 'railroad', 'moonlight', 'football']\n",
      "After Stemming the Words using Porter Stemmer:\n",
      "Word                PorterStemmer       Lancaster Stemmer   \n",
      "friend              friend              friend              \n",
      "friendship          friendship          friend              \n",
      "friends             friend              friend              \n",
      "friendships         friendship          friend              \n",
      "stabil              stabil              stabl               \n",
      "destabilize         destabil            dest                \n",
      "misunderstanding    misunderstand       misunderstand       \n",
      "railroad            railroad            railroad            \n",
      "moonlight           moonlight           moonlight           \n",
      "football            footbal             footbal             \n"
     ]
    }
   ],
   "source": [
    "# List of words using PorterStemmer and LancasterStemmer\n",
    "\n",
    "word_list=[\"friend\", \"friendship\", \"friends\", \"friendships\", \"stabil\", \"destabilize\", \"misunderstanding\", \"railroad\",\"moonlight\",\"football\"]\n",
    "\n",
    "print(\"The Original Word List\")\n",
    "print(word_list)\n",
    "\n",
    "print(\"After Stemming the Words using Porter Stemmer:\")\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"PorterStemmer\",\"Lancaster Stemmer\"))\n",
    "\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word,porter.stem(word),lancaster.stem(word)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4. Downloading neccessary modules to Lemmatize sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python310\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python310\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "%pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\divu2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\divu2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6. Declaring a sentence as a string & Lemmatizing the same sentence using WordNetLemmetizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original Sentence is:\n",
      "He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\n",
      "After Lemmatizing words using the WordNetLemmatizer:\n",
      "Words               Lemmatized words    \n",
      "He                  He                  \n",
      "was                 wa                  \n",
      "running             running             \n",
      "and                 and                 \n",
      "eating              eating              \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 ha                  \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swimming            \n",
      "after               after               \n",
      "playing             playing             \n",
      "long                long                \n",
      "hours               hour                \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "# Step-6 : Declaring a sentence as a string & Lemmatizing the same sentence using WordNetLemmetizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "print(\"The Original Sentence is:\")\n",
    "print(sentence)\n",
    "print(\"After Lemmatizing words using the WordNetLemmatizer:\")\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Words\", \"Lemmatized words\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word, wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 7. Importing necessary libraries for word sense disambiguation(WSD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 8. Declaring two different sentences with homonyms & performing WSD to fetch the sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 :\n",
      "This device is used to jam the signal.\n",
      "Meaning of the jam word in sentence 1 is :\n",
      "Synset('throng.v.01') press tightly together or cram\n",
      "\n",
      "Sentence 2 :\n",
      "This device is used to jam the signal.\n",
      "Meaning of the jam word in sentence 2 is :\n",
      "Synset('jam.v.05') get stuck and immobilized\n"
     ]
    }
   ],
   "source": [
    "sen1=\"This device is used to jam the signal.\"\n",
    "print(\"Sentence 1 :\")\n",
    "print(sen1)\n",
    "print(\"Meaning of the jam word in sentence 1 is :\")\n",
    "a1=lesk(word_tokenize('sen1'),'jam')\n",
    "\n",
    "print(a1,a1.definition())\n",
    "\n",
    "sen2=\"This device is used to jam the signal.\"\n",
    "print(\"\\nSentence 2 :\")\n",
    "print(sen2)\n",
    "print(\"Meaning of the jam word in sentence 2 is :\")\n",
    "a2=lesk(word_tokenize('I am stuck in a traffic jam'),'jam')\n",
    "\n",
    "print(a2,a2.definition())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 9 : Testing WSD with different sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('season.v.01') lend flavor to\n"
     ]
    }
   ],
   "source": [
    "# testing with some other data\n",
    "b1=lesk(word_tokenize('Apply the salt & other spices to the chicken to season it'),'season')\n",
    "print(b1,b1.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('season.n.01') a period of the year marked by special events or activities in some field\n"
     ]
    }
   ],
   "source": [
    "# testing with some data\n",
    "\n",
    "b2=lesk(word_tokenize(\"It'll be too humid inside in the rainy season\"),'season')\n",
    "print(b2,b2.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
